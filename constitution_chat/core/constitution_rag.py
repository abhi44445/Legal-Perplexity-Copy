"""
Constitution RAG Module
======================

Implements enhanced RAG (Retrieval-Augmented Generation) functionality with:
- DeepSeek R1 reasoning capabilities
- Constitutional legal question answering
- Citation validation and accuracy scoring
- Transparent reasoning process display

This module provides the core intelligence for constitutional legal assistance.
"""

import os
from typing import List, Optional, Dict, Any, Tuple, Union
from functools import lru_cache
import re
import time
from dotenv import load_dotenv
import sys

# Add parent directory for imports
sys.path.append('../..')
from constitution_chat.processing.performance_optimizer import performance_optimizer, performance_monitoring
from constitution_chat.processing.enhanced_reasoning_extractor import ReasoningChainExtractor

from langchain.schema import Document
from langchain.prompts import PromptTemplate
from constitution_chat.core.constitution_db import ConstitutionDatabase

# Load environment variables
load_dotenv()


class ConstitutionRAG:
    """
    Enhanced RAG system for constitutional legal assistance.
    
    Features:
    - DeepSeek R1 reasoning capabilities
    - 5-document retrieval for legal completeness
    - Citation validation and accuracy scoring
    - Transparent reasoning process
    """
    
    def __init__(self, 
                 constitution_db: Optional[ConstitutionDatabase] = None,
                 model_name: str = "deepseek/deepseek-r1-0528:free",
                 temperature: float = 0.1,
                 retrieval_k: int = 5):
        """
        Initialize Constitution RAG system.
        
        Args:
            constitution_db: Constitution database instance
            model_name: LLM model to use
            temperature: Model temperature for consistency
            retrieval_k: Number of documents to retrieve
        """
        self.constitution_db = constitution_db or ConstitutionDatabase()
        self.retrieval_k = retrieval_k
        
        # Initialize DeepSeek R1 model with OpenRouter
        self.llm = self._setup_llm(model_name, temperature)
        
        # Initialize enhanced reasoning extractor
        self.reasoning_extractor = ReasoningChainExtractor()
        
        # DeepSeek reasoning template
        self.reasoning_prompt = self._create_reasoning_prompt()
        
        # Constitutional article patterns for citation validation
        self.article_pattern = re.compile(r'(?:Article|Art\.?)\s+(\d+)|(?:^|\s)(\d+)\.(?=\s[A-Z])', re.IGNORECASE | re.MULTILINE)
        self.part_pattern = re.compile(r'Part\s+([IVXivx]+)', re.IGNORECASE)  # Support both upper and lowercase Roman numerals
        
    def _setup_llm(self, model_name: str, temperature: float):
        """Setup ChatOpenAI with OpenRouter for DeepSeek R1."""
        # First try to use real ChatOpenAI with a free model
        try:
            # Use OpenRouter with a free model
            from langchain_openai import ChatOpenAI
            
            # Use OpenRouter API (no API key required for free models)
            openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
            if not openrouter_api_key:
                # Use a free model that doesn't require API key
                print("Warning: OPENROUTER_API_KEY not found, using meta-llama/llama-3.1-8b-instruct:free")
                model_name = "meta-llama/llama-3.1-8b-instruct:free"
                openrouter_api_key = "optional"  # Some free models don't require a key
            
            return ChatOpenAI(
                model=model_name,
                api_key=openrouter_api_key,
                base_url="https://openrouter.ai/api/v1",
                temperature=temperature,
                max_tokens=2000,
                timeout=60,
                max_retries=3
            )
        except Exception as e:
            print(f"Warning: Failed to initialize ChatOpenAI ({e}), using improved mock LLM")
            return self._create_improved_mock_llm()
    
    def _create_improved_mock_llm(self):
        """Create an improved mock LLM that provides better constitutional responses."""
        class ImprovedMockLLM:
            def __init__(self):
                self.model_name = "improved_mock_constitutional_llm"
                
            def invoke(self, prompt):
                class MockResponse:
                    def __init__(self, query_context):
                        # Try to extract the query from the prompt
                        if "Question:" in query_context:
                            query = query_context.split("Question:")[-1].strip()
                        else:
                            query = "constitutional query"
                        
                        # Generate a more relevant response based on query keywords
                        self.content = self._generate_contextual_response(query, query_context)
                    
                    def _generate_contextual_response(self, query, context):
                        query_lower = query.lower()
                        
                        # Extract some context from the provided constitutional context
                        context_snippets = []
                        if "Constitutional Context:" in context:
                            context_section = context.split("Constitutional Context:")[1]
                            # Extract first few lines of relevant context
                            lines = context_section.split('\n')[:10]
                            context_snippets = [line.strip() for line in lines if line.strip()]
                        
                        # Reasoning section
                        thinking = """<thinking>
Let me analyze this constitutional question step by step:

1. IDENTIFY the constitutional area: Based on the query, this relates to constitutional provisions
2. LOCATE relevant articles: I'll reference the constitutional context provided
3. VERIFY article citations: I'll ensure accuracy in constitutional references  
4. CHECK for cross-references: I'll consider related constitutional provisions
5. ENSURE legal interpretation: I'll provide sound constitutional analysis
6. VALIDATE constitutional grounding: I'll base my answer on constitutional text
</thinking>

"""
                        
                        # Generate response based on query type
                        if any(word in query_lower for word in ['fundamental rights', 'article 19', 'freedom', 'rights']):
                            response = f"""Based on the constitutional provisions, here is the analysis:

**Fundamental Rights under the Constitution:**

The Constitution of India guarantees several fundamental rights in Part III:

**Article 19 - Freedom of Speech and Expression:**
- All citizens have the right to freedom of speech and expression
- Right to assemble peaceably and without arms
- Right to form associations or unions
- Freedom to move freely throughout India
- Right to reside and settle in any part of India
- Right to practice any profession or carry on occupation, trade, or business

**Constitutional Safeguards:**
These rights are subject to reasonable restrictions in the interests of:
- Sovereignty and integrity of India
- Security of the State
- Public order, decency, or morality
- Friendly relations with foreign States

{self._include_context_if_available(context_snippets)}

This analysis is based on Part III of the Constitution of India."""

                        elif any(word in query_lower for word in ['directive principles', 'dpsp', 'part iv']):
                            response = f"""Based on the constitutional provisions:

**Directive Principles of State Policy (Part IV):**

The Directive Principles are fundamental in the governance of the country and it shall be the duty of the State to apply these principles in making laws.

**Key Principles:**
- Article 39: Equal right to adequate means of livelihood
- Article 41: Right to work, education, and public assistance
- Article 44: Uniform civil code for citizens
- Article 45: Free and compulsory education for children
- Article 46: Promotion of educational and economic interests of weaker sections

**Constitutional Significance:**
- These principles are not enforceable by courts (Article 37)
- They are fundamental in governance and law-making
- They complement the Fundamental Rights

{self._include_context_if_available(context_snippets)}

This analysis is grounded in Part IV of the Constitution."""

                        elif any(word in query_lower for word in ['amendment', 'article 368', 'amend']):
                            response = f"""Based on constitutional provisions:

**Constitutional Amendment Process:**

**Article 368** provides the procedure for constitutional amendments:

**Types of Amendments:**
1. **Simple Majority** (some provisions)
2. **Special Majority** (most provisions) - majority of total membership + 2/3 of present and voting
3. **Special Majority + Ratification** (federal provisions) - requires ratification by half the states

**Key Limitations:**
- Basic structure doctrine (established in Kesavananda Bharati case)
- Parliament cannot alter the basic structure of the Constitution
- Certain core features are unamendable

{self._include_context_if_available(context_snippets)}

This analysis is based on Article 368 and constitutional jurisprudence."""

                        elif any(word in query_lower for word in ['reservation', 'quota', 'article 15', 'article 16']):
                            response = f"""Based on constitutional provisions:

**Reservations under the Constitution:**

**Constitutional Basis:**
- Article 15(4): Special provisions for socially and educationally backward classes
- Article 15(5): Reservations in educational institutions
- Article 16(4): Reservations in public employment
- Article 46: Promotion of educational and economic interests of weaker sections

**Scope of Reservations:**
- Scheduled Castes and Scheduled Tribes
- Other Backward Classes (OBCs)
- Economically Weaker Sections (EWS) - 103rd Amendment

**Constitutional Limits:**
- Must not exceed reasonable limits
- Should not affect efficiency of administration
- Based on backwardness, not just caste

{self._include_context_if_available(context_snippets)}

This analysis is grounded in constitutional provisions and judicial interpretations."""

                        else:
                            # Generic constitutional response
                            response = f"""Based on the constitutional framework:

**Constitutional Analysis:**

The Constitution of India provides a comprehensive framework for governance and rights protection. Key features include:

**Fundamental Rights (Part III):**
- Right to Equality (Articles 14-18)
- Right to Freedom (Articles 19-22)
- Right against Exploitation (Articles 23-24)
- Right to Freedom of Religion (Articles 25-28)
- Cultural and Educational Rights (Articles 29-30)
- Right to Constitutional Remedies (Article 32)

**Directive Principles (Part IV):**
- Guidelines for state policy
- Social and economic democracy
- Welfare state objectives

{self._include_context_if_available(context_snippets)}

This analysis is based on constitutional provisions and established jurisprudence."""

                        return thinking + response
                    
                    def _include_context_if_available(self, context_snippets):
                        if context_snippets:
                            relevant_context = []
                            for snippet in context_snippets[:3]:  # Use first 3 relevant snippets
                                if len(snippet) > 20:  # Only include meaningful snippets
                                    relevant_context.append(snippet)
                            
                            if relevant_context:
                                return f"\n\n**Relevant Constitutional Text:**\n" + "\n".join([f"â€¢ {snippet}" for snippet in relevant_context])
                        return ""
                
                return MockResponse(prompt)
        
        return ImprovedMockLLM()
    
    def _create_reasoning_prompt(self) -> PromptTemplate:
        """Create DeepSeek reasoning prompt template."""
        template = """<thinking>
Let me analyze this constitutional question step by step:

1. IDENTIFY the constitutional area being asked about
2. LOCATE relevant articles and provisions in the provided context
3. VERIFY article citations are accurate and complete
4. CHECK for cross-references to related constitutional provisions
5. ENSURE legal interpretation is sound and well-reasoned
6. VALIDATE that my answer is based on constitutional text, not assumption

Constitutional areas to consider:
- Fundamental Rights (Part III)
- Directive Principles (Part IV)
- Union and State relations (Part XI)
- Amendment procedures
- Emergency provisions
- Constitutional bodies and their powers

I need to be precise with article numbers and ensure accuracy.
</thinking>

Constitutional Context:
{context}

Question: {question}

Based on the constitutional provisions provided above, I will now provide a comprehensive legal analysis with proper citations:"""

        return PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
    
    @lru_cache(maxsize=128)
    def retrieve_relevant_context(self, query: str) -> List[Document]:
        """
        Retrieve relevant constitutional documents for the query with caching.
        
        Args:
            query: Legal question or search query
            
        Returns:
            List of relevant constitutional documents
        """
        # Get vectorstore and search for relevant content
        vectorstore = self.constitution_db.get_vectorstore()
        
        # Retrieve documents with similarity search
        documents = vectorstore.similarity_search(query, k=self.retrieval_k)
        
        return documents
    
    def extract_citations(self, text: str) -> Dict[str, List[str]]:
        """
        Extract article and part citations from text.
        
        Args:
            text: Text to extract citations from
            
        Returns:
            Dictionary with article and part citations
        """
        articles = []
        parts = []
        
        # Find article citations using improved pattern
        article_matches = self.article_pattern.findall(text)
        for match in article_matches:
            # match is a tuple from multiple capture groups
            article_num = match[0] if match[0] else match[1]  # First or second group
            if article_num:
                articles.append(f"Article {article_num}")
        
        # Find part citations and normalize case
        part_matches = self.part_pattern.findall(text)
        for part_num in part_matches:
            # Normalize to uppercase Roman numerals
            normalized_part = part_num.upper()
            parts.append(f"Part {normalized_part}")
        
        return {
            'articles': list(set(articles)),  # Remove duplicates
            'parts': list(set(parts))
        }
    
    def validate_citations(self, response_text: str, context_docs: List[Document]) -> Dict[str, Any]:
        """
        Validate citations in the response against context documents.
        
        Args:
            response_text: Generated response text
            context_docs: Context documents used for generation
            
        Returns:
            Citation validation results
        """
        # Extract citations from response
        response_citations = self.extract_citations(response_text)
        
        # Extract all valid citations from context
        context_text = "\n".join([doc.page_content for doc in context_docs])
        valid_citations = self.extract_citations(context_text)
        
        # Calculate accuracy
        total_response_citations = len(response_citations['articles']) + len(response_citations['parts'])
        
        # Initialize variables for all cases
        valid_articles = set()
        valid_parts = set()
        
        if total_response_citations == 0:
            citation_accuracy = 1.0  # No citations to validate
        else:
            valid_articles = set(response_citations['articles']).intersection(set(valid_citations['articles']))
            valid_parts = set(response_citations['parts']).intersection(set(valid_citations['parts']))
            valid_count = len(valid_articles) + len(valid_parts)
            citation_accuracy = valid_count / total_response_citations
        
        return {
            'citation_accuracy': citation_accuracy,
            'total_citations': total_response_citations,
            'valid_citations': len(valid_articles) + len(valid_parts),
            'response_citations': response_citations,
            'valid_articles': list(valid_articles),
            'valid_parts': list(valid_parts),
            'invalid_citations': {
                'articles': list(set(response_citations['articles']) - set(valid_citations['articles'])),
                'parts': list(set(response_citations['parts']) - set(valid_citations['parts']))
            }
        }
    
    @performance_monitoring
    def generate_response_optimized(self, question: str, user_type: str = "general") -> Dict[str, Any]:
        """
        Generate a comprehensive constitutional response with reasoning and performance optimization.
        
        Args:
            question: Constitutional legal question
            user_type: Type of user (lawyer, law_student, general_public)
            
        Returns:
            Dictionary containing response, reasoning, citations, and metadata
        """
        start_time = time.time()
        
        # Retrieve relevant constitutional context
        context_docs = self.retrieve_relevant_context(question)
        
        # Prepare context for prompt
        context_text = "\n\n".join([
            f"Document {i+1}:\n{doc.page_content}" 
            for i, doc in enumerate(context_docs)
        ])
        
        # Generate response with reasoning
        prompt = self.reasoning_prompt.format(
            context=context_text,
            question=question
        )
        
        response = self.llm.invoke(prompt)
        response_text = response.content
        
        # Extract reasoning using enhanced extractor
        reasoning_result = self.reasoning_extractor.extract_reasoning_chain(response_text)
        
        # Clean response text (remove thinking tags)
        answer = self.reasoning_extractor.clean_response_text(response_text)
        
        # Validate citations
        citation_validation = self.validate_citations(answer, context_docs)
        
        # Calculate response time
        response_time = time.time() - start_time
        
        return {
            'question': question,
            'answer': answer,
            'reasoning': reasoning_result['raw_reasoning'],
            'reasoning_chain': reasoning_result,  # Full reasoning analysis
            'context_documents': len(context_docs),
            'citation_validation': citation_validation,
            'response_time': response_time,
            'user_type': user_type,
            'metadata': {
                'model': getattr(self.llm, 'model_name', 'mock_llm'),
                'retrieval_k': self.retrieval_k,
                'constitutional_context': [doc.metadata for doc in context_docs],
                'reasoning_extraction_success': reasoning_result['extraction_success'],
                'reasoning_quality': reasoning_result['quality_analysis']
            }
        }

    def generate_response_direct(self, question: str, user_type: str = "general") -> Dict[str, Any]:
        """
        Generate response directly without performance optimization.
        This bypasses the performance optimizer that may cause hanging.
        
        Args:
            question: Constitutional legal question
            user_type: Type of user (lawyer, law_student, general_public)
            
        Returns:
            Dictionary containing response, reasoning, citations, and metadata
        """
        start_time = time.time()
        
        try:
            # Retrieve relevant constitutional context
            context_docs = self.retrieve_relevant_context(question)
            
            # Prepare context for prompt
            context_text = "\n\n".join([
                f"Document {i+1}:\n{doc.page_content}" 
                for i, doc in enumerate(context_docs)
            ])
            
            # Generate response with reasoning
            prompt = self.reasoning_prompt.format(
                context=context_text,
                question=question
            )
            
            response = self.llm.invoke(prompt)
            response_text = response.content
            
            # Extract reasoning using enhanced extractor
            reasoning_result = self.reasoning_extractor.extract_reasoning_chain(response_text)
            
            # Clean response text (remove thinking tags)
            answer = self.reasoning_extractor.clean_response_text(response_text)
            
            # Validate citations
            citation_validation = self.validate_citations(answer, context_docs)
            
            # Calculate response time
            response_time = time.time() - start_time
            
            return {
                'question': question,
                'answer': answer,
                'reasoning': reasoning_result['raw_reasoning'],
                'reasoning_chain': reasoning_result,  # Full reasoning analysis
                'context_documents': len(context_docs),
                'citation_validation': citation_validation,
                'response_time': response_time,
                'user_type': user_type,
                'status': 'success',
                'metadata': {
                    'model': getattr(self.llm, 'model_name', 'unknown'),
                    'retrieval_k': self.retrieval_k,
                    'constitutional_context': [doc.metadata for doc in context_docs],
                    'reasoning_extraction_success': reasoning_result['extraction_success'],
                    'reasoning_quality': reasoning_result['quality_analysis'],
                    'generation_method': 'direct'
                }
            }
            
        except Exception as e:
            return {
                'question': question,
                'status': 'error',
                'error': str(e),
                'answer': None,
                'reasoning': None,
                'citation_validation': None,
                'response_time': time.time() - start_time,
                'user_type': user_type,
                'metadata': {'generation_method': 'direct', 'error_type': type(e).__name__}
            }
    
    def ask_constitutional_question(self, question: str, user_type: str = "general") -> Dict[str, Any]:
        """
        Main interface for asking constitutional questions with performance optimization.
        
        Args:
            question: Constitutional legal question
            user_type: Type of user (lawyer, law_student, general_public)
            
        Returns:
            Complete response with reasoning and validation
        """
        try:
            result = self.generate_response_optimized(question, user_type)
            
            # Add success status
            result['status'] = 'success'
            result['error'] = None
            
            return result
            
        except Exception as e:
            return {
                'question': question,
                'status': 'error',
                'error': str(e),
                'answer': None,
                'reasoning': None,
                'citation_validation': None,
                'response_time': 0,
                'user_type': user_type
            }
    
    def get_performance_statistics(self) -> Dict[str, Any]:
        """Get performance statistics from the optimizer."""
        return performance_optimizer.get_performance_stats()
    
    def clear_cache(self) -> None:
        """Clear the response cache."""
        performance_optimizer.clear_cache()
    
    def reset_performance_metrics(self) -> None:
        """Reset performance metrics."""
        performance_optimizer.reset_metrics()


def main():
    """Test the Constitution RAG functionality."""
    print("Initializing Constitution RAG...")
    
    # Initialize RAG system
    rag = ConstitutionRAG()
    
    # Test questions
    test_questions = [
        "What are fundamental rights under Article 19?",
        "Explain the procedure for constitutional amendment",
        "What are directive principles of state policy?"
    ]
    
    for question in test_questions:
        print(f"\n{'='*60}")
        print(f"Question: {question}")
        print('='*60)
        
        result = rag.ask_constitutional_question(question)
        
        if result['status'] == 'success':
            print(f"Response Time: {result['response_time']:.2f} seconds")
            print(f"Documents Retrieved: {result['context_documents']}")
            print(f"Citation Accuracy: {result['citation_validation']['citation_accuracy']:.2%}")
            
            print(f"\nReasoning Process:")
            print(result['reasoning'][:300] + "..." if len(result['reasoning']) > 300 else result['reasoning'])
            
            print(f"\nAnswer:")
            print(result['answer'][:400] + "..." if len(result['answer']) > 400 else result['answer'])
        else:
            print(f"Error: {result['error']}")


if __name__ == "__main__":
    main()